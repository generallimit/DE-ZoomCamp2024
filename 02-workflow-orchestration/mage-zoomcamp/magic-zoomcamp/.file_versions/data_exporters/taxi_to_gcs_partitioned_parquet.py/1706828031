import pyarrow as pa
import pyarrow.parquet as pq
import os


if 'data_exporter' not in globals():
    from mage_ai.data_preparation.decorators import data_exporter

os.environ['GOOGLE_APPLICATION_CREDENTIAL'] = '/home/src/astute-impulse-412600-49e302200507.json'

bucket_name = 'astute-impulse-412600-mage-bucket'
projec_id = 'astute-impulse-412600'

table_name = 'nyc_taxi_data'

root_path = f'{bucket_name}/{table_name}'

def list_blobs(bucket_name):
    """Lists all the blobs in the bucket."""
    # bucket_name = "your-bucket-name"

    storage_client = storage.Client()

    # Note: Client.list_blobs requires at least package version 1.17.0.
    blobs = storage_client.list_blobs(bucket_name)

    # Note: The call returns a response only when the iterator is consumed.
    for blob in blobs:
        print(blob.name)

# @data_exporter
# def export_data(data, *args, **kwargs):
#     data['tpep_pickup_date'] = data['tpep_pickup_datetime'].dt.date

#     table = pa.Table.from_pandas(data)

#     gcs = pa.fs.GcsFileSystem()

#     pq.write_to_dataset(
#         table,
#         root_path=root_path,
#         partition_cols=['tpep_pickup_date'],
#         filesystem=gcs
#     )